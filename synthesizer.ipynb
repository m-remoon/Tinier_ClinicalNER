{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5c/q5s6s04d5q38x2r_7p2x7v7c0000gn/T/ipykernel_86929/2276608828.py:6: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat_model = ChatOpenAI(model_name=\"gpt-4o\", openai_api_key=\"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\")\n",
      "/var/folders/5c/q5s6s04d5q38x2r_7p2x7v7c0000gn/T/ipykernel_86929/2276608828.py:72: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=chat_model, prompt=prompt_template)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Initialize the ChatGPT model\n",
    "chat_model = ChatOpenAI(model_name=\"gpt-4o\", openai_api_key=\"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\")\n",
    "\n",
    "# Define a prompt template\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"text\"],\n",
    "    template=\n",
    "    \"\"\"\n",
    "You are a medical data extraction assistant. Given the following text, extract generate corresponding labels in the BIO format.\n",
    "\n",
    "### Input Text:\n",
    "{text}\n",
    "\n",
    "### Instructions:\n",
    "1. **Maintain Consistent Formatting**:\n",
    "   - **Casing**: Use sentence casing for all fields (e.g., \"Daily\" instead of \"DAILY\").\n",
    "   - **Numeric Dosage**: Always use numeric formats (e.g., \"1-2\" instead of \"One or Two\").\n",
    "   - **Strength**: Ensure all strengths include units (e.g., \"81 mg\").\n",
    "   - **Form**: If the form has multiple components (e.g., \"Tablet, Delayed Release (E.C.)\"), **always list the base form first**, followed by additional descriptors separated by commas.\n",
    "\n",
    "2. **Align Labels in BIO Format**:\n",
    "   - Use the following tags for labeling:\n",
    "     - B-DRUG / I-DRUG  \n",
    "     - B-STRENGTH / I-STRENGTH  \n",
    "     - B-FORM / I-FORM  \n",
    "     - B-DOSAGE / I-DOSAGE  \n",
    "     - B-FREQUENCY / I-FREQUENCY  \n",
    "     - B-ROUTE / I-ROUTE  \n",
    "     - B-REASON / I-REASON  \n",
    "     - O (for other tokens)\n",
    "\n",
    "\n",
    "Multi-word fields (e.g., \"Tablet, Delayed Release (E.C.)\") should be split, with appropriate BIO labels assigned to each part.\n",
    "Each token in the input must have a corresponding BIO tag. for example, if the input text split on white space is 22, it must have 22 bio labels!!!\n",
    "\n",
    "Here is an Expected Output Example based off the following input:\n",
    "1. Sertraline 50 mg Tablet Sig: One (1) Tablet PO DAILY for depression.\n",
    "2. Levothyroxine 75 mcg Tablet Sig: One (1) Tablet PO DAILY for hypothyroidism.\n",
    "\n",
    "--\n",
    "1. [O, B-DRUG, B-STRENGTH, I-STRENGTH, B-FORM, O, B-DOSAGE, B-DOSAGE, B-FORM, B-ROUTE, B-FREQUENCY, O, B-REASON]\n",
    "2. [O, B-DRUG, B-STRENGTH, I-STRENGTH, B-FORM, O, B-DOSAGE, B-DOSAGE, B-FORM, B-ROUTE, B-FREQUENCY, O, B-REASON]\n",
    "--\n",
    "\n",
    "Make sure your response is formatted exactly like what's between the two '--' but not including those '--'.\n",
    "\n",
    "Notice how there are 13 bio labels, since there are 13 splits if you were to split \"1. Sertraline 50 mg Tablet Sig: One (1) Tablet PO DAILY for depression.\" This is crucial! \n",
    "\n",
    "Multi-token fields (e.g., \"Two (2)\") must use B- and I- tags appropriately.\n",
    "Filler words like \"on\", \"the\", \"first\" should receive O tags to maintain alignment.\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Create a chain that uses the model and the prompt\n",
    "llm_chain = LLMChain(llm=chat_model, prompt=prompt_template)\n",
    "\n",
    "# Function to get a response for a single prompt\n",
    "def get_response(prompt):\n",
    "    response = llm_chain.run(prompt)\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_names = ['r_838', 'r_390', 'r_384', 'r_409', 'r_780', 'r_958', 'r_794', 'r_757', 'r_756', 'r_959', 'r_781', 'r_408', 'r_385', 'r_391', 'r_839', 'r_387', 'r_393', 'r_378', 'r_783', 'r_768', 'r_754', 'r_755', 'r_769', 'r_782', 'r_379', 'r_392', 'r_386', 'r_37', 'r_382', 'r_396', 'r_355', 'r_369', 'r_792', 'r_786', 'r_962', 'r_779', 'r_778', 'r_963', 'r_787', 'r_793', 'r_368', 'r_397', 'r_383', 'r_618', 'r_395', 'r_381', 'r_356', 'r_785', 'r_791', 'r_949', 'r_961', 'r_753', 'r_960', 'r_948', 'r_790', 'r_784', 'r_357', 'r_380', 'r_394', 'r_873', 'r_867', 'r_42', 'r_56', 'r_81', 'r_287', 'r_293', 'r_278', 'r_913', 'r_912', 'r_279', 'r_292', 'r_286', 'r_80', 'r_57', 'r_43', 'r_866', 'r_872', 'r_69', 'r_864', 'r_870', 'r_55', 'r_858', 'r_41', 'r_82', 'r_290', 'r_284', 'r_509', 'r_247', 'r_910', 'r_938', 'r_939', 'r_911', 'r_246', 'r_508', 'r_285', 'r_291', 'r_83', 'r_40', 'r_859', 'r_54', 'r_871', 'r_865', 'r_68', 'r_50', 'r_849', 'r_44', 'r_861', 'r_875', 'r_78', 'r_87', 'r_295', 'r_281', 'r_929', 'r_915', 'r_914', 'r_928', 'r_280', 'r_294', 'r_86', 'r_79', 'r_874', 'r_860', 'r_45', 'r_848', 'r_51', 'r_47', 'r_53', 'r_876', 'r_862', 'r_84', 'r_90', 'r_309', 'r_282', 'r_296', 'r_269', 'r_916', 'r_917', 'r_268', 'r_297', 'r_283', 'r_308', 'r_91', 'r_85', 'r_863', 'r_877', 'r_52', 'r_46', 'r_852', 'r_846', 'r_63', 'r_77', 'r_88', 'r_885', 'r_311', 'r_305', 'r_259', 'r_265', 'r_271', 'r_926', 'r_932', 'r_933', 'r_927', 'r_270', 'r_264', 'r_258', 'r_304', 'r_310', 'r_884', 'r_89', 'r_76', 'r_62', 'r_847', 'r_853', 'r_48', 'r_845', 'r_851', 'r_74', 'r_879', 'r_60', 'r_306', 'r_312', 'r_299', 'r_272', 'r_266', 'r_931', 'r_925', 'r_919', 'r_918', 'r_924', 'r_930', 'r_267', 'r_273', 'r_298', 'r_307', 'r_61', 'r_878', 'r_75', 'r_850', 'r_844', 'r_49', 'r_71', 'r_868', 'r_65', 'r_840', 'r_854', 'r_59', 'r_883', 'r_303', 'r_288', 'r_277', 'r_263', 'r_934', 'r_920', 'r_921', 'r_935', 'r_909', 'r_262', 'r_276', 'r_289', 'r_302', 'r_882', 'r_58', 'r_855', 'r_841', 'r_64', 'r_869', 'r_70', 'r_66', 'r_72', 'r_857', 'r_843', 'r_880', 'r_300', 'r_260', 'r_274', 'r_248', 'r_923', 'r_937', 'r_936', 'r_922', 'r_275', 'r_261', 'r_507', 'r_301', 'r_881', 'r_842', 'r_856', 'r_73', 'r_67', 'r_616', 'r_399', 'r_372', 'r_400', 'r_366', 'r_945', 'r_789', 'r_951', 'r_762', 'r_776', 'r_777', 'r_763', 'r_950', 'r_788', 'r_944', 'r_401', 'r_367', 'r_373', 'r_398', 'r_617', 'r_832', 'r_359', 'r_365', 'r_403', 'r_371', 'r_952', 'r_946', 'r_775', 'r_761', 'r_760', 'r_774', 'r_947', 'r_953', 'r_370', 'r_364', 'r_402', 'r_358', 'r_833', 'r_837', 'r_406', 'r_360', 'r_374', 'r_957', 'r_943', 'r_770', 'r_764', 'r_758', 'r_759', 'r_765', 'r_771', 'r_942', 'r_956', 'r_375', 'r_407', 'r_361', 'r_836', 'r_834', 'r_39', 'r_388', 'r_377', 'r_363', 'r_405', 'r_940', 'r_954', 'r_767', 'r_773', 'r_772', 'r_766', 'r_955', 'r_941', 'r_362', 'r_404', 'r_376', 'r_389', 'r_38', 'r_835']\n",
    "\n",
    "def extract_information_from_folder(input_folder_path, output_folder_path, redone_output_folder_path):\n",
    "    # Get all .txt files in the folder and sort them numerically\n",
    "    files = sorted(\n",
    "        [f for f in os.listdir(input_folder_path) if f.endswith('.txt') and f.replace('.txt', '') in base_names],\n",
    "        key=lambda x: int(''.join(filter(str.isdigit, x)))  # Extract numeric part for sorting\n",
    "    )\n",
    "        \n",
    "    # trial_files = files[:2]\n",
    "    \n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(input_folder_path, file_name)\n",
    "\n",
    "        try:\n",
    "            # Read the input text from the file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                input_text = file.read().strip()\n",
    "\n",
    "            # Chain 1: Extract structured information\n",
    "            # Ensuring the input text is passed properly to the LLM chain\n",
    "            output_1 = get_response({'text': input_text})\n",
    "\n",
    "            # Save the first output to the output folder\n",
    "            output_file_name = f\"{os.path.splitext(file_name)[0]}_redone_response.txt\"\n",
    "            output_file_path = os.path.join(redone_output_folder_path, output_file_name)\n",
    "            \n",
    "            if os.path.exists(output_file_path):\n",
    "                print(f\"Warning: {output_file_name} already exists. Skipping.\")\n",
    "                continue  # Skip writing if the file exists\n",
    "\n",
    "            with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(output_1)\n",
    "\n",
    "            print(f\"Processed {file_name} with Chain 1 and saved response to {output_file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: r_37_redone_response.txt already exists. Skipping.\n",
      "Warning: r_38_redone_response.txt already exists. Skipping.\n",
      "Processed r_39.txt with Chain 1 and saved response to r_39_redone_response.txt\n",
      "Processed r_40.txt with Chain 1 and saved response to r_40_redone_response.txt\n",
      "Processed r_41.txt with Chain 1 and saved response to r_41_redone_response.txt\n",
      "Processed r_42.txt with Chain 1 and saved response to r_42_redone_response.txt\n",
      "Processed r_43.txt with Chain 1 and saved response to r_43_redone_response.txt\n",
      "Processed r_44.txt with Chain 1 and saved response to r_44_redone_response.txt\n",
      "Processed r_45.txt with Chain 1 and saved response to r_45_redone_response.txt\n",
      "Processed r_46.txt with Chain 1 and saved response to r_46_redone_response.txt\n",
      "Processed r_47.txt with Chain 1 and saved response to r_47_redone_response.txt\n",
      "Processed r_48.txt with Chain 1 and saved response to r_48_redone_response.txt\n",
      "Processed r_49.txt with Chain 1 and saved response to r_49_redone_response.txt\n",
      "Processed r_50.txt with Chain 1 and saved response to r_50_redone_response.txt\n",
      "Processed r_51.txt with Chain 1 and saved response to r_51_redone_response.txt\n",
      "Processed r_52.txt with Chain 1 and saved response to r_52_redone_response.txt\n",
      "Processed r_53.txt with Chain 1 and saved response to r_53_redone_response.txt\n",
      "Processed r_54.txt with Chain 1 and saved response to r_54_redone_response.txt\n"
     ]
    }
   ],
   "source": [
    "input_folder_path = '/Users/remon.m/Desktop/Y4S2/Thesis/Coding/Synth/input'\n",
    "output_folder_path = '/Users/remon.m/Desktop/Y4S2/Thesis/Coding/Synth/output'\n",
    "redone_output_folder_path = '/Users/remon.m/Desktop/Y4S2/Thesis/Coding/Synth/output'\n",
    "\n",
    "extract_information_from_folder(input_folder_path, output_folder_path, redone_output_folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PharmBERT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
